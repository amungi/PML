---
title: "Practical Machine Learning - Course Project"
author: "Ashish Mungi"
date: "14 August 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. People regularly quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, we use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants, who were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).

Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.

This dataset is available as the Weight Lifting Exercise Dataset from the website: <http://groupware.les.inf.puc-rio.br/har>

## Data

The training data for this project are at: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv>

The test data are at: <https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv>

## Goal of the Project

The goal of the project is to predict the manner in which the 6 participants did the exercise. This is the "classe" variable in the training set. Any of the other variables can be used to predict with.

## Load Libraries

```{r echo=TRUE}
library(caret)
library(randomForest)
library(rpart.plot)
```

## Read the Training Data File

It is assumed that the training and test data files are downloaded from the URLs indicated above and present in the working directory of the R project.

On viewing the CSV files manually before loading the data, it is observed that missing values are indicated by "NA","#DIV/0!" and "" strings.

```{r echo=TRUE}
# read CSV file with training data
trainingData <- read.csv("pml-training.csv", na.strings = c("NA","#DIV/0!",""))
testingData <- read.csv("pml-testing.csv", na.strings = c("NA","#DIV/0!",""))
```

## Partition the Training Data

The training data is partitioned into 2 sets: 60% training and 40% testing.

A seed is set for reproducibility.

```{r echo=TRUE}
set.seed(54321)
inTrain <- createDataPartition(trainingData$classe, p=0.6, list = FALSE)
myTrain <- trainingData[inTrain,]
myTest <- trainingData[-inTrain,]
dim(myTrain)
dim(myTest)
```

## Clean the Data

1. Remove zero covariates from myTrain and myTest

```{r echo=TRUE}
nzv_Train <- nearZeroVar(myTrain, saveMetrics = TRUE)
myTrain <- myTrain[,nzv_Train$nzv==FALSE]
dim(myTrain)

nzv_Test <- nearZeroVar(myTest, saveMetrics = TRUE)
myTest <- myTest[,nzv_Test$nzv==FALSE]
dim(myTest)
```

2. Remove the first column (which is an ID column) from the myTrain set

```{r echo=TRUE}
myTrain <- myTrain[c(-1)]
```

3. Clean variables with too many missing values in the myTrain set. Assume 50% threshold.

```{r echo=TRUE}
myT <- myTrain # assign to a temporary variable myT
for(i in 1:length(myTrain)) {
    if( sum( is.na(myTrain[,i] ) ) / nrow(myTrain) >= 0.5) { # check threshold
        for(j in 1:length(myT)) {
            if( length( grep(names(myTrain[i]), names(myT)[j]) ) == 1) {
                myT <- myT[,-j]
            }   
        }
    }
}

# Assign myT back to the original variable name
myTrain <- myT
rm(myT) # remove the temporary variable myT
```

4. Similarly transform the myTest and testingData sets to allow only variables that are also in myTrain

```{r echo=TRUE}
c1 <- colnames(myTrain)
c1
c2 <- colnames(myTrain[, -58])  # remove the classe column
c2
myTest <- myTest[c1]            # transform myTest
testingData <- testingData[c2]  # transform testingData

dim(myTest)
dim(testingData)
```

5. Coerce the data into the same type for proper functioning of the machine learning algorithms.

```{r echo=TRUE}
for (i in 1:length(testingData) ) {
    for(j in 1:length(myTrain)) {
        if( length( grep(names(myTrain[i]), names(testingData)[j]) ) == 1)  {
            class(testingData[j]) <- class(myTrain[i])
        }      
    }      
}

# To get the same class between testingData and myTrain
testingData <- rbind(myTrain[2, -58] , testingData)
testingData <- testingData[-1,]
```

## Prediction with Decision Trees

```{r echo=TRUE}
set.seed(54321)
modFitDT <- rpart(classe ~ ., data=myTrain, method="class")
plot(modFitDT, uniform=TRUE)
text(modFitDT, use.n=TRUE, all=TRUE, cex = 0.7)
predictionDT <- predict(modFitDT, myTest, type = "class")
cmTree <- confusionMatrix(predictionDT,myTest$classe)
cmTree
accTree <- round(cmTree$overall['Accuracy'],4)
paste("DECISION TREE CONFUSION MATRIX: Accuracy = ",accTree)
paste("EXPECTED OUT-OF-SAMPLE ERROR RATE with Decision Trees = ",(1 - accTree))
```

## Prdiction with Random Forests

```{r echo=TRUE}
set.seed(54321)
modFitRF <- randomForest(classe ~ ., data=myTrain)
predictionRF <- predict(modFitRF, myTest, type = "class")
cmRF <- confusionMatrix(predictionRF,myTest$classe)
cmRF
accRF <- round(cmRF$overall['Accuracy'],4)
paste("RANDOM FOREST CONFUSION MATRIX: Accuracy = ",accRF)
paste("EXPECTED OUT-OF-SAMPLE ERROR RATE with Random Forests = ",(1 - accRF))
plot(modFitRF)
```

## Conclusion

Random Forest method gives better accuracy than Decision Trees. The expected Out-of-Sample Error Rate is **`r (1 - accRF)`**

## Predictions for Test Data

```{r echo=TRUE}
predictionTESTING <- predict(modFitRF, testingData, type = "class")
predictionTESTING
```
